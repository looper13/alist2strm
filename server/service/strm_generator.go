package service

import (
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"

	"github.com/MccRay-s/alist2strm/model/filehistory"
	"github.com/MccRay-s/alist2strm/model/task"
	"github.com/MccRay-s/alist2strm/model/tasklog"
	"github.com/MccRay-s/alist2strm/repository"
	"go.uber.org/zap"
)

// StrmConfig STRM é…ç½®ç»“æ„
type StrmConfig struct {
	DefaultSuffix string `json:"defaultSuffix"` // é»˜è®¤åª’ä½“æ–‡ä»¶åç¼€
	ReplaceSuffix bool   `json:"replaceSuffix"` // æ˜¯å¦æ›¿æ¢åç¼€
	URLEncode     bool   `json:"urlEncode"`     // æ˜¯å¦URLç¼–ç 
}

// FileType æ–‡ä»¶ç±»å‹æšä¸¾
type FileType int

const (
	FileTypeMedia FileType = iota
	FileTypeMetadata
	FileTypeSubtitle
	FileTypeOther
)

// ProcessedFile å¤„ç†åçš„æ–‡ä»¶ä¿¡æ¯
type ProcessedFile struct {
	SourceFile   *AListFile
	TargetPath   string
	FileType     FileType
	Success      bool
	ErrorMessage string
}

// FileProcessResult æ–‡ä»¶å¤„ç†ç»“æœ
type FileProcessResult struct {
	Entry      FileEntry
	Processed  *ProcessedFile
	FileType   FileType
	Success    bool
	IsSubtitle bool
	IsMetadata bool
}

// FileProcessQueue æ–‡ä»¶å¤„ç†é˜Ÿåˆ—ç±»å‹
type FileProcessQueue struct {
	StrmFiles     []FileEntry  // ç”¨äºç”Ÿæˆ STRM çš„åª’ä½“æ–‡ä»¶é˜Ÿåˆ—
	DownloadFiles []FileEntry  // éœ€è¦ä¸‹è½½çš„æ–‡ä»¶é˜Ÿåˆ— (å­—å¹•ã€å…ƒæ•°æ®)
	FilesMutex    sync.RWMutex // ç”¨äºå®‰å…¨è®¿é—®é˜Ÿåˆ—çš„äº’æ–¥é”
}

// ProcessingStats æ–‡ä»¶å¤„ç†ç»Ÿè®¡ä¿¡æ¯
type ProcessingStats struct {
	TotalFiles             int          // æ‰«æåˆ°çš„æ€»æ–‡ä»¶æ•°
	GeneratedFiles         int          // æˆåŠŸç”Ÿæˆçš„ STRM æ–‡ä»¶
	SkippedFiles           int          // è·³è¿‡çš„æ–‡ä»¶
	MetadataProcessed      int          // å¤„ç†çš„å…ƒæ•°æ®æ–‡ä»¶
	SubtitleProcessed      int          // å¤„ç†çš„å­—å¹•æ–‡ä»¶
	ScanFinished           bool         // ç›®å½•æ‰«ææ˜¯å¦å·²å®Œæˆ
	StrmProcessingDone     bool         // STRM æ–‡ä»¶å¤„ç†æ˜¯å¦å·²å®Œæˆ
	DownloadProcessingDone bool         // ä¸‹è½½æ–‡ä»¶å¤„ç†æ˜¯å¦å·²å®Œæˆ
	Mutex                  sync.RWMutex // ç”¨äºå®‰å…¨è®¿é—®ç»Ÿè®¡çš„äº’æ–¥é”
}

// StrmGeneratorService STRM æ–‡ä»¶ç”ŸæˆæœåŠ¡
type StrmGeneratorService struct {
	alistService *AListService
	logger       *zap.Logger
	mu           sync.RWMutex
	queue        *FileProcessQueue // æ–‡ä»¶å¤„ç†é˜Ÿåˆ—
	stats        *ProcessingStats  // å¤„ç†ç»Ÿè®¡
}

var (
	strmGeneratorInstance *StrmGeneratorService
	strmGeneratorOnce     sync.Once
)

// GetStrmGeneratorService è·å– STRM ç”ŸæˆæœåŠ¡å®ä¾‹
func GetStrmGeneratorService() *StrmGeneratorService {
	strmGeneratorOnce.Do(func() {
		strmGeneratorInstance = &StrmGeneratorService{
			queue: &FileProcessQueue{
				StrmFiles:     make([]FileEntry, 0),
				DownloadFiles: make([]FileEntry, 0),
			},
			stats: &ProcessingStats{},
		}
	})
	return strmGeneratorInstance
}

// Initialize åˆå§‹åŒ–æœåŠ¡
func (s *StrmGeneratorService) Initialize(logger *zap.Logger) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.logger = logger
	s.alistService = GetAListService()

	// åˆå§‹åŒ–é˜Ÿåˆ—å’Œç»Ÿè®¡ä¿¡æ¯
	s.queue = &FileProcessQueue{
		StrmFiles:     make([]FileEntry, 0),
		DownloadFiles: make([]FileEntry, 0),
	}
	s.stats = &ProcessingStats{}

	logger.Info("STRM ç”ŸæˆæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
}

// IsInitialized æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²åˆå§‹åŒ–
func (s *StrmGeneratorService) IsInitialized() bool {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return s.logger != nil && s.alistService != nil
}

// GenerateStrmFiles ç”Ÿæˆ STRM æ–‡ä»¶ä¸»æ–¹æ³•
func (s *StrmGeneratorService) GenerateStrmFiles(taskID uint) error {
	// æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²åˆå§‹åŒ–
	if !s.IsInitialized() {
		return fmt.Errorf("STRM ç”ŸæˆæœåŠ¡æœªæ­£ç¡®åˆå§‹åŒ–")
	}

	// è·å–ä»»åŠ¡ä¿¡æ¯
	taskInfo, err := repository.Task.GetByID(taskID)
	if err != nil {
		return fmt.Errorf("è·å–ä»»åŠ¡ä¿¡æ¯å¤±è´¥: %w", err)
	}

	// é‡ç½®å¤„ç†é˜Ÿåˆ—å’Œç»Ÿè®¡ä¿¡æ¯
	s.queue = &FileProcessQueue{
		StrmFiles:     make([]FileEntry, 0),
		DownloadFiles: make([]FileEntry, 0),
	}
	s.stats = &ProcessingStats{}

	// åˆ›å»ºä»»åŠ¡æ—¥å¿—
	taskLog := &tasklog.TaskLog{
		TaskID:        taskID,
		Status:        tasklog.TaskLogStatusRunning,
		Message:       "å¼€å§‹ç”Ÿæˆ STRM æ–‡ä»¶",
		StartTime:     time.Now(),
		TotalFile:     0,
		GeneratedFile: 0,
		SkipFile:      0,
		MetadataCount: 0,
		SubtitleCount: 0,
	}

	taskLogID, err := s.createTaskLog(taskLog)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºä»»åŠ¡æ—¥å¿—å¤±è´¥: %w", err)
	}

	// åŠ è½½ STRM é…ç½®
	strmConfig, err := s.loadStrmConfig()
	if err != nil {
		s.updateTaskLogWithError(taskLogID, "åŠ è½½ STRM é…ç½®å¤±è´¥: "+err.Error())
		return err
	}

	// å¼€å§‹å¤„ç†æ–‡ä»¶
	s.logger.Info("å¼€å§‹å¤„ç†ä»»åŠ¡",
		zap.Uint("taskId", taskID),
		zap.String("sourcePath", taskInfo.SourcePath),
		zap.String("targetPath", taskInfo.TargetPath))

	// å…ˆå¯åŠ¨STRMæ–‡ä»¶å¤„ç†åç¨‹ï¼ˆå¹¶å‘ï¼‰ï¼Œè®©å®ƒç­‰å¾…é˜Ÿåˆ—ä¸­çš„é¡¹ç›®
	var strmProcessingErr error
	var wg sync.WaitGroup
	wg.Add(1)

	// åˆ›å»ºä¿¡å·é€šé“ï¼Œç”¨äºå‘STRMå¤„ç†åç¨‹é€šçŸ¥æ‰«æå®Œæˆ
	strmScanDoneChan := make(chan bool)

	// 1. å…ˆå¯åŠ¨STRMæ–‡ä»¶ç”Ÿæˆåç¨‹ï¼ˆå¹¶å‘ï¼‰ï¼Œå®ƒä¼šç«‹å³å¼€å§‹å¤„ç†åª’ä½“æ–‡ä»¶
	go func() {
		defer wg.Done()
		strmProcessingErr = s.processStrmFileQueueAsync(taskInfo, strmConfig, taskLogID, strmScanDoneChan)
	}()

	// ç°åœ¨å¼€å§‹é€’å½’æ‰«æï¼Œè¾¹æ‰«æè¾¹å°†åª’ä½“æ–‡ä»¶åŠ å…¥é˜Ÿåˆ—ï¼ˆç«‹å³å¤„ç†ï¼‰
	startTime := time.Now()
	err = s.scanDirectoryRecursive(taskInfo, strmConfig, taskLogID, taskInfo.SourcePath, taskInfo.TargetPath)
	if err != nil {
		// é€šçŸ¥STRMåç¨‹æ‰«æå·²ç»“æŸï¼ˆå¤±è´¥ï¼‰
		close(strmScanDoneChan)

		// ç­‰å¾…STRMåç¨‹ç»“æŸ
		wg.Wait()

		s.updateTaskLogWithError(taskLogID, "æ‰«æç›®å½•å¤±è´¥: "+err.Error())
		return err
	}
	scanDuration := time.Since(startTime)

	// ç›®å½•æ‰«æå®Œæˆåï¼Œæ ‡è®°æ‰«æç»“æŸï¼Œå¹¶æ›´æ–°ä»»åŠ¡æ—¥å¿—ä¸­çš„æ€»æ–‡ä»¶æ•°
	s.stats.Mutex.Lock()
	s.stats.ScanFinished = true
	totalFiles := s.stats.TotalFiles
	s.stats.Mutex.Unlock()

	s.logger.Info("ç›®å½•æ‰«æå®Œæˆ",
		zap.Int("æ€»æ–‡ä»¶æ•°", totalFiles),
		zap.Duration("æ‰«æç”¨æ—¶", scanDuration),
		zap.Int("STRMé˜Ÿåˆ—é•¿åº¦", len(s.queue.StrmFiles)),
		zap.Int("ä¸‹è½½é˜Ÿåˆ—é•¿åº¦", len(s.queue.DownloadFiles)))

	// æ›´æ–°ä»»åŠ¡æ—¥å¿—ä¸­çš„æ€»æ–‡ä»¶æ•°
	updateTotalData := map[string]interface{}{
		"total_file": totalFiles,
	}
	if updateErr := repository.TaskLog.UpdatePartial(taskLogID, updateTotalData); updateErr != nil {
		s.logger.Error("æ›´æ–°ä»»åŠ¡æ—¥å¿—æ€»æ–‡ä»¶æ•°å¤±è´¥", zap.Error(updateErr))
	}

	// é€šçŸ¥STRMåç¨‹æ‰«æå·²ç»“æŸ
	close(strmScanDoneChan)

	// å¯åŠ¨ä¸‹è½½æ–‡ä»¶å¤„ç†åç¨‹ï¼ˆä¸²è¡Œï¼‰
	var downloadProcessingErr error
	wg.Add(1)
	go func() {
		defer wg.Done()
		downloadProcessingErr = s.processDownloadFileQueue(taskInfo, strmConfig, taskLogID)
	}()

	// ç­‰å¾…æ‰€æœ‰å¤„ç†éƒ½å®Œæˆ
	wg.Wait()

	// æ›´æ–°ä»»åŠ¡æ—¥å¿—
	s.stats.Mutex.RLock()
	generatedFiles := s.stats.GeneratedFiles
	skippedFiles := s.stats.SkippedFiles
	metadataFiles := s.stats.MetadataProcessed
	subtitleFiles := s.stats.SubtitleProcessed
	s.stats.Mutex.RUnlock()

	endTime := time.Now()
	status := tasklog.TaskLogStatusCompleted
	message := "STRM æ–‡ä»¶ç”Ÿæˆå®Œæˆ"

	// å¦‚æœä»»ä¸€å¤„ç†å‡ºé”™ï¼Œæ ‡è®°ä»»åŠ¡å¤±è´¥
	if strmProcessingErr != nil {
		status = tasklog.TaskLogStatusFailed
		message = "STRM æ–‡ä»¶ç”Ÿæˆå¤±è´¥: " + strmProcessingErr.Error()
		err = strmProcessingErr
	} else if downloadProcessingErr != nil {
		status = tasklog.TaskLogStatusFailed
		message = "ä¸‹è½½æ–‡ä»¶å¤„ç†å¤±è´¥: " + downloadProcessingErr.Error()
		err = downloadProcessingErr
	}

	// è·å–å½“å‰ä»»åŠ¡æ—¥å¿—è®°å½•ä»¥è·å–å¼€å§‹æ—¶é—´
	taskLogRecord, logErr := repository.TaskLog.GetByID(taskLogID)

	// è®¡ç®—æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
	var durationSeconds int64 = 0
	if logErr == nil {
		durationSeconds = int64(endTime.Sub(taskLogRecord.StartTime).Seconds())
		s.logger.Info("è®¡ç®—ä»»åŠ¡æŒç»­æ—¶é—´",
			zap.Uint("taskLogID", taskLogID),
			zap.Int64("duration", durationSeconds),
			zap.String("taskName", taskInfo.Name))
	} else {
		s.logger.Warn("æ— æ³•è·å–ä»»åŠ¡æ—¥å¿—è®°å½•ï¼Œæ— æ³•è®¡ç®—æŒç»­æ—¶é—´",
			zap.Error(logErr),
			zap.Uint("taskLogID", taskLogID))
	}

	updateData := map[string]interface{}{
		"status":         status,
		"message":        message,
		"end_time":       &endTime,
		"duration":       durationSeconds,
		"total_file":     totalFiles,
		"generated_file": generatedFiles,
		"skip_file":      skippedFiles,
		"metadata_count": metadataFiles,
		"subtitle_count": subtitleFiles,
	}

	if updateErr := repository.TaskLog.UpdatePartial(taskLogID, updateData); updateErr != nil {
		s.logger.Error("æ›´æ–°ä»»åŠ¡æ—¥å¿—å¤±è´¥", zap.Error(updateErr))
	}

	// å‘é€Telegramé€šçŸ¥
	notifyErr := s.sendTelegramNotification(taskInfo, taskLogID, status, durationSeconds, updateData)
	if notifyErr != nil {
		s.logger.Error("å‘é€Telegramé€šçŸ¥å¤±è´¥", zap.Error(notifyErr))
	}

	return err
}

// loadStrmConfig åŠ è½½ STRM é…ç½®
func (s *StrmGeneratorService) loadStrmConfig() (*StrmConfig, error) {
	config, err := repository.Config.GetByCode("STRM")
	if err != nil {
		return nil, fmt.Errorf("è·å– STRM é…ç½®å¤±è´¥: %w", err)
	}

	var strmConfig StrmConfig
	if err := json.Unmarshal([]byte(config.Value), &strmConfig); err != nil {
		return nil, fmt.Errorf("è§£æ STRM é…ç½®å¤±è´¥: %w", err)
	}

	return &strmConfig, nil
}

// FileEntry æ–‡ä»¶æ¡ç›®ï¼ŒåŒ…å«å®Œæ•´ä¿¡æ¯
type FileEntry struct {
	File           *AListFile
	FileType       FileType
	SourcePath     string
	TargetPath     string
	NameWithoutExt string // ä¸å«æ‰©å±•åçš„æ–‡ä»¶å
}

// processDirectory æ–¹æ³•å·²è¢«é‡æ„ï¼Œä½¿ç”¨äº†æ–°çš„ä»»åŠ¡é˜Ÿåˆ—è®¾è®¡

// scanDirectoryRecursive é€’å½’æ‰«æç›®å½•ï¼Œåªæ”¶é›†æ–‡ä»¶ä¿¡æ¯ï¼Œä¸è¿›è¡Œå¤„ç†
func (s *StrmGeneratorService) scanDirectoryRecursive(taskInfo *task.Task, strmConfig *StrmConfig,
	taskLogID uint, sourcePath, targetPath string) error {

	// è·å–å½“å‰ç›®å½•çš„æ–‡ä»¶åˆ—è¡¨
	files, err := s.alistService.ListFiles(sourcePath)
	if err != nil {
		return fmt.Errorf("è·å–ç›®å½•æ–‡ä»¶åˆ—è¡¨å¤±è´¥ [%s]: %w", sourcePath, err)
	}

	s.logger.Info("æ‰«æç›®å½•",
		zap.String("sourcePath", sourcePath),
		zap.String("targetPath", targetPath),
		zap.Int("fileCount", len(files)))

	// åˆ›å»ºç›®æ ‡ç›®å½•
	if err := os.MkdirAll(targetPath, 0755); err != nil {
		return fmt.Errorf("åˆ›å»ºç›®æ ‡ç›®å½•å¤±è´¥ [%s]: %w", targetPath, err)
	}

	// æ”¶é›†å„ç§æ–‡ä»¶ä¿¡æ¯
	var mediaFileEntries []FileEntry
	var subtitleFileEntries []FileEntry
	var metadataFileEntries []FileEntry
	var directoryFiles []*AListFile

	// å¢åŠ æ€»æ–‡ä»¶è®¡æ•°
	s.stats.Mutex.Lock()
	s.stats.TotalFiles += len(files)
	totalFiles := s.stats.TotalFiles
	s.stats.Mutex.Unlock()

	// å®šæœŸæ›´æ–°ä»»åŠ¡æ—¥å¿—ä¸­çš„æ€»æ–‡ä»¶æ•°
	if totalFiles%100 == 0 {
		updateData := map[string]interface{}{
			"total_file": totalFiles,
		}
		if updateErr := repository.TaskLog.UpdatePartial(taskLogID, updateData); updateErr != nil {
			s.logger.Error("æ›´æ–°ä»»åŠ¡æ—¥å¿—æ€»æ–‡ä»¶æ•°å¤±è´¥", zap.Error(updateErr))
		}
	}

	// å…ˆå¯¹æ–‡ä»¶è¿›è¡Œåˆ†ç±»
	for _, file := range files {
		if file.IsDir {
			directoryFiles = append(directoryFiles, &file)
			continue
		}

		// æ„å»ºå®Œæ•´è·¯å¾„
		currentSourcePath := filepath.Join(sourcePath, file.Name)
		currentTargetPath := filepath.Join(targetPath, file.Name)

		// ç¡®å®šæ–‡ä»¶ç±»å‹
		fileType := s.determineFileType(&file, taskInfo, strmConfig)

		// è·å–ä¸å«æ‰©å±•åçš„æ–‡ä»¶å
		nameWithoutExt := strings.TrimSuffix(file.Name, filepath.Ext(file.Name))

		entry := FileEntry{
			File:           &file,
			FileType:       fileType,
			SourcePath:     currentSourcePath,
			TargetPath:     currentTargetPath,
			NameWithoutExt: nameWithoutExt,
		}

		// æŒ‰ç±»å‹åˆ†ç»„
		switch fileType {
		case FileTypeMedia:
			mediaFileEntries = append(mediaFileEntries, entry)
		case FileTypeSubtitle:
			subtitleFileEntries = append(subtitleFileEntries, entry)
		case FileTypeMetadata:
			metadataFileEntries = append(metadataFileEntries, entry)
		default:
			// å…¶ä»–æ–‡ä»¶ç±»å‹ä¸å¤„ç†ï¼Œä½†è®¡å…¥è·³è¿‡æ–‡ä»¶
			s.stats.Mutex.Lock()
			s.stats.SkippedFiles++
			s.stats.Mutex.Unlock()
		}
	}

	// ç­›é€‰éœ€è¦å¤„ç†çš„å­—å¹•æ–‡ä»¶ï¼ˆéœ€è¦ä¸åª’ä½“æ–‡ä»¶åŒ¹é…ï¼‰
	var matchedSubtitleEntries []FileEntry
	for _, subEntry := range subtitleFileEntries {
		matched := false

		// æ£€æŸ¥æ˜¯å¦ä¸ä»»ä½•åª’ä½“æ–‡ä»¶åŒ¹é…
		for _, mediaEntry := range mediaFileEntries {
			// å­—å¹•æ–‡ä»¶åéœ€è¦ä»¥åª’ä½“æ–‡ä»¶åä¸ºå‰ç¼€ï¼ˆå¦‚movie.mp4ä¸movie.srtï¼‰
			if strings.HasPrefix(subEntry.NameWithoutExt, mediaEntry.NameWithoutExt) {
				matched = true
				break
			}
		}

		if matched {
			matchedSubtitleEntries = append(matchedSubtitleEntries, subEntry)
		} else {
			s.logger.Info("è·³è¿‡æœªåŒ¹é…çš„å­—å¹•æ–‡ä»¶",
				zap.String("fileName", subEntry.File.Name),
				zap.String("path", subEntry.SourcePath))

			s.stats.Mutex.Lock()
			s.stats.SkippedFiles++
			s.stats.Mutex.Unlock()
		}
	}

	// å°†æ”¶é›†åˆ°çš„æ–‡ä»¶æ·»åŠ åˆ°ç›¸åº”çš„å¤„ç†é˜Ÿåˆ—
	// åª’ä½“æ–‡ä»¶ç«‹å³æ·»åŠ åˆ°STRMç”Ÿæˆé˜Ÿåˆ—ï¼Œè¿™æ ·è¾¹æ‰«æè¾¹å¤„ç†
	if len(mediaFileEntries) > 0 {
		s.queue.FilesMutex.Lock()
		// æ·»åŠ åª’ä½“æ–‡ä»¶åˆ° STRM ç”Ÿæˆé˜Ÿåˆ—
		s.queue.StrmFiles = append(s.queue.StrmFiles, mediaFileEntries...)
		s.queue.FilesMutex.Unlock()
	}

	// ä¸‹è½½æ–‡ä»¶å…ˆæ”¶é›†ï¼Œç­‰æ‰«æç»“æŸåå†å¤„ç†
	if len(matchedSubtitleEntries) > 0 || len(metadataFileEntries) > 0 {
		s.queue.FilesMutex.Lock()
		// æ·»åŠ åŒ¹é…çš„å­—å¹•å’Œå…ƒæ•°æ®æ–‡ä»¶åˆ°ä¸‹è½½é˜Ÿåˆ—
		s.queue.DownloadFiles = append(s.queue.DownloadFiles, matchedSubtitleEntries...)
		s.queue.DownloadFiles = append(s.queue.DownloadFiles, metadataFileEntries...)
		s.queue.FilesMutex.Unlock()
	}

	// é€’å½’å¤„ç†å­ç›®å½•
	for _, dirFile := range directoryFiles {
		currentSourcePath := filepath.Join(sourcePath, dirFile.Name)
		currentTargetPath := filepath.Join(targetPath, dirFile.Name)

		// é€’å½’å¤„ç†å­ç›®å½•
		if err := s.scanDirectoryRecursive(taskInfo, strmConfig, taskLogID, currentSourcePath, currentTargetPath); err != nil {
			return err
		}
	}

	return nil
}

// determineFileType ç¡®å®šæ–‡ä»¶ç±»å‹
func (s *StrmGeneratorService) determineFileType(file *AListFile, taskInfo *task.Task, strmConfig *StrmConfig) FileType {
	ext := strings.ToLower(filepath.Ext(file.Name))

	// æ£€æŸ¥æ˜¯å¦ä¸ºåª’ä½“æ–‡ä»¶
	mediaExtensions := strings.Split(strings.ToLower(strmConfig.DefaultSuffix), ",")
	for _, mediaExt := range mediaExtensions {
		if ext == "."+strings.TrimSpace(mediaExt) {
			return FileTypeMedia
		}
	}

	// æ£€æŸ¥æ˜¯å¦ä¸ºå…ƒæ•°æ®æ–‡ä»¶
	if taskInfo.DownloadMetadata {
		metadataExtensions := strings.Split(strings.ToLower(taskInfo.MetadataExtensions), ",")
		for _, metaExt := range metadataExtensions {
			if ext == "."+strings.TrimSpace(metaExt) {
				return FileTypeMetadata
			}
		}
	}

	// æ£€æŸ¥æ˜¯å¦ä¸ºå­—å¹•æ–‡ä»¶
	if taskInfo.DownloadSubtitle {
		subtitleExtensions := strings.Split(strings.ToLower(taskInfo.SubtitleExtensions), ",")
		for _, subExt := range subtitleExtensions {
			if ext == "."+strings.TrimSpace(subExt) {
				return FileTypeSubtitle
			}
		}
	}

	return FileTypeOther
}

// processFile å¤„ç†å•ä¸ªæ–‡ä»¶
func (s *StrmGeneratorService) processFile(file *AListFile, fileType FileType, taskInfo *task.Task, strmConfig *StrmConfig, taskLogID uint, sourcePath, targetPath string) *ProcessedFile {
	result := &ProcessedFile{
		SourceFile: file,
		TargetPath: targetPath,
		FileType:   fileType,
		Success:    false,
	}

	// è®°å½•å¼€å§‹å¤„ç†æ–‡ä»¶
	s.logger.Debug("å¼€å§‹å¤„ç†æ–‡ä»¶",
		zap.String("æ–‡ä»¶å", file.Name),
		zap.String("æ–‡ä»¶ç±»å‹", getFileTypeString(fileType)),
		zap.String("æºè·¯å¾„", sourcePath),
		zap.String("ç›®æ ‡è·¯å¾„", targetPath),
		zap.Int64("æ–‡ä»¶å¤§å°", file.Size))

	switch fileType {
	case FileTypeMedia:
		// ç”Ÿæˆ STRM æ–‡ä»¶ - ä»…ä½¿ç”¨ AListFile ä¸­å·²æœ‰ä¿¡æ¯
		var strmFilePath string
		result.Success, result.ErrorMessage, strmFilePath = s.generateStrmFile(file, strmConfig, taskInfo, sourcePath, targetPath)
		if result.Success {
			// å¦‚æœæˆåŠŸç”ŸæˆSTRMæ–‡ä»¶ï¼Œæ›´æ–°ç›®æ ‡è·¯å¾„ä¸ºå®é™…çš„STRMæ–‡ä»¶è·¯å¾„
			result.TargetPath = strmFilePath
		}
	case FileTypeMetadata, FileTypeSubtitle:
		// ä¸‹è½½å…ƒæ•°æ®æˆ–å­—å¹•æ–‡ä»¶ - ä»…ä½¿ç”¨ AListFile ä¸­å·²æœ‰ä¿¡æ¯
		result.Success, result.ErrorMessage = s.downloadFile(file, sourcePath, targetPath, taskInfo)
	default:
		result.ErrorMessage = "ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œå·²è·³è¿‡"
	}

	// è®°å½•å¤„ç†ç»“æœ
	if !result.Success {
		s.logger.Warn("å¤„ç†æ–‡ä»¶å¤±è´¥",
			zap.String("æ–‡ä»¶å", file.Name),
			zap.String("æ–‡ä»¶ç±»å‹", getFileTypeString(fileType)),
			zap.String("é”™è¯¯", result.ErrorMessage))
	} else {
		s.logger.Debug("å¤„ç†æ–‡ä»¶æˆåŠŸ",
			zap.String("æ–‡ä»¶å", file.Name),
			zap.String("æ–‡ä»¶ç±»å‹", getFileTypeString(fileType)))
	}

	return result
}

// getFileTypeString è·å–æ–‡ä»¶ç±»å‹çš„å­—ç¬¦ä¸²è¡¨ç¤º
func getFileTypeString(fileType FileType) string {
	switch fileType {
	case FileTypeMedia:
		return "åª’ä½“æ–‡ä»¶"
	case FileTypeMetadata:
		return "å…ƒæ•°æ®æ–‡ä»¶"
	case FileTypeSubtitle:
		return "å­—å¹•æ–‡ä»¶"
	default:
		return "å…¶ä»–æ–‡ä»¶"
	}
}

// generateStrmFile ç”Ÿæˆ STRM æ–‡ä»¶ï¼Œè¿”å›æˆåŠŸçŠ¶æ€ã€é”™è¯¯æ¶ˆæ¯å’ŒSTRMæ–‡ä»¶è·¯å¾„
func (s *StrmGeneratorService) generateStrmFile(file *AListFile, strmConfig *StrmConfig, taskConfig *task.Task, sourcePath, targetPath string) (bool, string, string) {
	// å¤„ç†è·¯å¾„å’Œæ–‡ä»¶åçš„ URL ç¼–ç 
	dirPath := filepath.Dir(sourcePath)
	fileName := file.Name

	// æ ¹æ® URLEncode é…ç½®å†³å®šæ˜¯å¦éœ€è¦å¯¹è·¯å¾„è¿›è¡Œç¼–ç 
	if strmConfig.URLEncode {
		// å°†è·¯å¾„åˆ†å‰²ä¸ºå„ä¸ªéƒ¨åˆ†ï¼Œå¯¹æ¯éƒ¨åˆ†è¿›è¡Œå•ç‹¬ç¼–ç ï¼Œç„¶åé‡æ–°è¿æ¥
		// è¿™ä¸ Node.js ç‰ˆæœ¬çš„å¤„ç†æ–¹å¼ç›¸åŒ: path.split('/').map(encodeURIComponent).join('/')
		pathParts := strings.Split(dirPath, "/")
		for i, part := range pathParts {
			pathParts[i] = url.PathEscape(part)
		}
		dirPath = strings.Join(pathParts, "/")

		// åŒæ ·å¤„ç†æ–‡ä»¶å
		fileName = url.PathEscape(fileName)

		s.logger.Debug("è¿›è¡Œäº†URLç¼–ç ",
			zap.String("åŸè·¯å¾„", filepath.Dir(sourcePath)),
			zap.String("ç¼–ç åè·¯å¾„", dirPath),
			zap.String("åŸæ–‡ä»¶å", file.Name),
			zap.String("ç¼–ç åæ–‡ä»¶å", fileName))
	}

	// æ„å»º STRM æ–‡ä»¶å†…å®¹ - ç›´æ¥ä½¿ç”¨ AListFile ä¸­çš„ä¿¡æ¯ï¼Œé¿å…å¤šä½™çš„ API è°ƒç”¨
	// æ³¨æ„ï¼šGetFileURL æ–¹æ³•ä¸ä¼šå‘èµ·é¢å¤–çš„ API è¯·æ±‚ï¼Œä»…ä½¿ç”¨é…ç½®å’Œå‚æ•°æ„å»º URL
	fileURL := s.alistService.GetFileURL(dirPath, fileName, file.Sign)
	if fileURL == "" {
		return false, "æ— æ³•ç”Ÿæˆæ–‡ä»¶URLï¼Œè¯·æ£€æŸ¥ AList é…ç½®æ˜¯å¦å®Œæ•´", ""
	}

	// ç”Ÿæˆ STRM æ–‡ä»¶å
	var strmFileName string
	if strmConfig.ReplaceSuffix {
		// æ›¿æ¢åç¼€ä¸º .strm
		nameWithoutExt := strings.TrimSuffix(file.Name, filepath.Ext(file.Name))
		strmFileName = nameWithoutExt + ".strm"
	} else {
		// åœ¨åŸæ–‡ä»¶ååæ·»åŠ  .strm
		strmFileName = file.Name + ".strm"
	}

	// æ„å»ºå®Œæ•´çš„ STRM æ–‡ä»¶è·¯å¾„
	strmFilePath := filepath.Join(filepath.Dir(targetPath), strmFileName)

	// æ£€æŸ¥æ˜¯å¦éœ€è¦è¦†ç›–ç°æœ‰æ–‡ä»¶
	if !s.shouldOverwrite(strmFilePath, taskConfig) {
		return false, "æ–‡ä»¶å·²å­˜åœ¨ä¸”ä¸å…è®¸è¦†ç›–", strmFilePath
	}

	// ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
	if err := os.MkdirAll(filepath.Dir(strmFilePath), 0755); err != nil {
		return false, fmt.Sprintf("åˆ›å»ºç›®æ ‡ç›®å½•å¤±è´¥: %v", err), strmFilePath
	}

	// å†™å…¥ STRM æ–‡ä»¶
	if err := os.WriteFile(strmFilePath, []byte(fileURL), 0644); err != nil {
		return false, fmt.Sprintf("å†™å…¥ STRM æ–‡ä»¶å¤±è´¥: %v", err), strmFilePath
	}

	s.logger.Info("ç”Ÿæˆ STRM æ–‡ä»¶æˆåŠŸ",
		zap.String("sourceFile", file.Name),
		zap.String("strmFile", strmFilePath),
		zap.String("url", fileURL))

	return true, "", strmFilePath
}

// downloadFile ä¸‹è½½æ–‡ä»¶ï¼ˆå…ƒæ•°æ®å’Œå­—å¹•ï¼‰
func (s *StrmGeneratorService) downloadFile(file *AListFile, sourcePath, targetPath string, taskConfig *task.Task) (bool, string) {

	if _, err := os.Stat(targetPath); err == nil {
		return false, "æ–‡ä»¶å·²å­˜åœ¨"
	}

	// ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
	if err := os.MkdirAll(filepath.Dir(targetPath), 0755); err != nil {
		return false, fmt.Sprintf("åˆ›å»ºç›®æ ‡ç›®å½•å¤±è´¥: %v", err)
	}

	// è·å– STRM é…ç½®ä»¥æ£€æŸ¥æ˜¯å¦éœ€è¦ URL ç¼–ç 
	strmConfig, err := s.loadStrmConfig()
	if err != nil {
		return false, fmt.Sprintf("åŠ è½½ STRM é…ç½®å¤±è´¥: %v", err)
	}

	// å¤„ç†è·¯å¾„å’Œæ–‡ä»¶å
	dirPath := filepath.Dir(sourcePath)
	fileName := file.Name

	// æ ¹æ® URLEncode é…ç½®å†³å®šæ˜¯å¦éœ€è¦å¯¹è·¯å¾„è¿›è¡Œç¼–ç 
	if strmConfig.URLEncode {
		// å¯¹è·¯å¾„å„éƒ¨åˆ†å•ç‹¬ç¼–ç 
		pathParts := strings.Split(dirPath, "/")
		for i, part := range pathParts {
			pathParts[i] = url.PathEscape(part)
		}
		dirPath = strings.Join(pathParts, "/")

		// å¯¹æ–‡ä»¶åç¼–ç 
		fileName = url.PathEscape(fileName)
	}

	// ç›´æ¥ä½¿ç”¨ AListFile ä¸­çš„ä¿¡æ¯æ„å»ºæ–‡ä»¶ URLï¼Œä¸éœ€è¦é¢å¤–çš„ API è°ƒç”¨
	// æ³¨æ„ï¼šGetFileURL æ–¹æ³•ä¸ä¼šå‘èµ·é¢å¤–çš„ API è¯·æ±‚ï¼Œä»…ä½¿ç”¨é…ç½®å’Œå‚æ•°æ„å»º URL
	fileURL := s.alistService.GetFileURL(dirPath, fileName, file.Sign)
	if fileURL == "" {
		return false, "æ— æ³•ç”Ÿæˆæ–‡ä»¶ä¸‹è½½URLï¼Œè¯·æ£€æŸ¥ AList é…ç½®æ˜¯å¦å®Œæ•´"
	}

	// å®ç° HTTP ä¸‹è½½é€»è¾‘
	if err := s.downloadFileFromURL(fileURL, targetPath); err != nil {
		return false, fmt.Sprintf("ä¸‹è½½æ–‡ä»¶å¤±è´¥: %v", err)
	}

	s.logger.Info("ä¸‹è½½æ–‡ä»¶æˆåŠŸ",
		zap.String("sourceFile", file.Name),
		zap.String("targetPath", targetPath),
		zap.String("size", humanizeSize(file.Size)))

	return true, ""
}

// humanizeSize å°†å­—èŠ‚å¤§å°è½¬æ¢ä¸ºå‹å¥½çš„å­—ç¬¦ä¸²è¡¨ç¤º
func humanizeSize(bytes int64) string {
	const unit = 1024
	if bytes < unit {
		return fmt.Sprintf("%d B", bytes)
	}
	div, exp := int64(unit), 0
	for n := bytes / unit; n >= unit; n /= unit {
		div *= unit
		exp++
	}
	return fmt.Sprintf("%.1f %ciB", float64(bytes)/float64(div), "KMGTPE"[exp])
}

// downloadFileFromURL ä» URL ä¸‹è½½æ–‡ä»¶
func (s *StrmGeneratorService) downloadFileFromURL(fileURL, targetPath string) error {
	// åˆ›å»º HTTP å®¢æˆ·ç«¯
	client := &http.Client{
		Timeout: 60 * time.Second,
	}

	// å‘é€ GET è¯·æ±‚
	resp, err := client.Get(fileURL)
	if err != nil {
		return fmt.Errorf("ä¸‹è½½æ–‡ä»¶å¤±è´¥: %w", err)
	}
	defer resp.Body.Close()

	// æ£€æŸ¥å“åº”çŠ¶æ€
	if resp.StatusCode != http.StatusOK {
		return fmt.Errorf("ä¸‹è½½æ–‡ä»¶å¤±è´¥ï¼ŒçŠ¶æ€ç : %d", resp.StatusCode)
	}

	// ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
	if err := os.MkdirAll(filepath.Dir(targetPath), 0755); err != nil {
		return fmt.Errorf("åˆ›å»ºç›®æ ‡ç›®å½•å¤±è´¥: %w", err)
	}

	// åˆ›å»ºç›®æ ‡æ–‡ä»¶
	file, err := os.Create(targetPath)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤±è´¥: %w", err)
	}
	defer file.Close()

	// å¤åˆ¶å†…å®¹
	_, err = io.Copy(file, resp.Body)
	if err != nil {
		return fmt.Errorf("å†™å…¥æ–‡ä»¶å¤±è´¥: %w", err)
	}

	return nil
}

// shouldOverwrite æ£€æŸ¥æ˜¯å¦åº”è¯¥è¦†ç›–æ–‡ä»¶
func (s *StrmGeneratorService) shouldOverwrite(filePath string, taskConfig *task.Task) bool {
	// å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¯ä»¥åˆ›å»º
	if _, err := os.Stat(filePath); os.IsNotExist(err) {
		return true
	}

	// æ ¹æ®ä»»åŠ¡é…ç½®çš„ Overwrite å­—æ®µå†³å®šæ˜¯å¦è¦†ç›–
	return taskConfig.Overwrite
}

// recordFileHistory è®°å½•æ–‡ä»¶å†å²
func (s *StrmGeneratorService) recordFileHistory(taskID, taskLogID uint, file *AListFile, sourcePath, targetPath string, fileType FileType, success bool) {
	if !success {
		return // åªè®°å½•æˆåŠŸå¤„ç†çš„æ–‡ä»¶
	}

	fileTypeStr := s.getFileTypeString(fileType)

	// è·å–æ–‡ä»¶Hash
	hash := ""
	if file.HashInfo.Sha1 != "" {
		hash = file.HashInfo.Sha1
	}

	// è®°å½•æ–‡ä»¶ç±»å‹å’Œæ˜¯å¦æœ‰Hashå€¼
	s.logger.Debug("å¤„ç†æ–‡ä»¶å†å²è®°å½•",
		zap.String("fileName", file.Name),
		zap.String("fileType", fileTypeStr),
		zap.Bool("hasHash", hash != ""),
		zap.String("hash", hash))

	// æ ¹æ®HashæŸ¥æ‰¾ç°æœ‰è®°å½•ï¼ˆåªæœ‰å½“Hashæœ‰å€¼æ—¶æ‰æŸ¥æ‰¾ï¼‰
	if hash != "" {
		existingRecord, err := repository.FileHistory.GetByHash(hash)
		if err == nil && existingRecord != nil {
			// æ‰¾åˆ°ç°æœ‰è®°å½•ï¼Œæ›´æ–°è€Œä¸æ˜¯åˆ›å»º
			now := time.Now()
			updateData := map[string]interface{}{
				"task_id":     taskID,
				"task_log_id": taskLogID,
				"updated_at":  now,
				"file_size":   file.Size,
				"modified_at": &file.Modified,
			}

			if err := repository.FileHistory.UpdateByID(existingRecord.ID, updateData); err != nil {
				s.logger.Error("æ›´æ–°æ–‡ä»¶å†å²è®°å½•å¤±è´¥",
					zap.String("fileName", file.Name),
					zap.String("hash", hash),
					zap.Error(err))
			} else {
				s.logger.Info("æ›´æ–°ç°æœ‰æ–‡ä»¶å†å²è®°å½•",
					zap.String("fileName", file.Name),
					zap.String("hash", hash),
					zap.String("fileType", fileTypeStr),
					zap.Uint("oldTaskID", existingRecord.TaskID),
					zap.Uint("newTaskID", taskID))
			}
			return
		}
	}

	// æ²¡æœ‰æ‰¾åˆ°ç°æœ‰è®°å½•æˆ–è€…æ²¡æœ‰Hashï¼Œåˆ›å»ºæ–°è®°å½•
	fileHistory := &filehistory.FileHistory{
		TaskID:         taskID,
		TaskLogID:      taskLogID,
		FileName:       file.Name,
		SourcePath:     sourcePath,
		TargetFilePath: targetPath,
		FileSize:       file.Size,
		FileType:       fileTypeStr,
		FileSuffix:     filepath.Ext(file.Name),
		IsStrm:         fileType == FileTypeMedia, // å¦‚æœæ˜¯åª’ä½“æ–‡ä»¶ç±»å‹ï¼Œåˆ™æ ‡è®°ä¸ºSTRMæ–‡ä»¶
		ModifiedAt:     &file.Modified,
		Hash:           hash,
	}

	if err := repository.FileHistory.Create(fileHistory); err != nil {
		s.logger.Error("è®°å½•æ–‡ä»¶å†å²å¤±è´¥",
			zap.String("fileName", file.Name),
			zap.Error(err))
	}
}

// getFileTypeString è·å–æ–‡ä»¶ç±»å‹å­—ç¬¦ä¸²
func (s *StrmGeneratorService) getFileTypeString(fileType FileType) string {
	switch fileType {
	case FileTypeMedia:
		return "media"
	case FileTypeMetadata:
		return "metadata"
	case FileTypeSubtitle:
		return "subtitle"
	default:
		return "other"
	}
}

// createTaskLog åˆ›å»ºä»»åŠ¡æ—¥å¿—
func (s *StrmGeneratorService) createTaskLog(taskLog *tasklog.TaskLog) (uint, error) {
	if err := repository.TaskLog.Create(taskLog); err != nil {
		return 0, err
	}
	return taskLog.ID, nil
}

// updateTaskLogWithError æ›´æ–°ä»»åŠ¡æ—¥å¿—ä¸ºé”™è¯¯çŠ¶æ€
func (s *StrmGeneratorService) updateTaskLogWithError(taskLogID uint, errorMessage string) {
	// è·å–å½“å‰ä»»åŠ¡æ—¥å¿—è®°å½•ä»¥è·å–å¼€å§‹æ—¶é—´
	taskLog, err := repository.TaskLog.GetByID(taskLogID)
	if err != nil {
		s.logger.Error("è·å–ä»»åŠ¡æ—¥å¿—å¤±è´¥", zap.Error(err))
		return
	}

	// è®¡ç®—æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
	endTime := time.Now()
	durationSeconds := int64(endTime.Sub(taskLog.StartTime).Seconds())

	updateData := map[string]interface{}{
		"status":   tasklog.TaskLogStatusFailed,
		"message":  errorMessage,
		"end_time": &endTime,
		"duration": durationSeconds,
	}

	if err := repository.TaskLog.UpdatePartial(taskLogID, updateData); err != nil {
		s.logger.Error("æ›´æ–°ä»»åŠ¡æ—¥å¿—å¤±è´¥", zap.Error(err))
	} else {
		s.logger.Debug("å·²æ›´æ–°ä»»åŠ¡æ—¥å¿—æŒç»­æ—¶é—´",
			zap.Uint("taskLogID", taskLogID),
			zap.Int64("duration", durationSeconds))
	}
}

// sendTelegramNotification å‘é€Telegramé€šçŸ¥
func (s *StrmGeneratorService) sendTelegramNotification(taskInfo *task.Task, taskLogID uint, status string, duration int64, stats map[string]interface{}) error {
	// Telegram Boté…ç½®ï¼ˆå®é™…åº”ç”¨ä¸­åº”ä»é…ç½®æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ä¸­è¯»å–ï¼‰
	const (
		enableNotification = true                                                 // æ˜¯å¦å¯ç”¨Telegramé€šçŸ¥
		botToken           = "467857328346:AAGwEGenWJYec1irqG26wJMoWxQHs6HArC0eE" // æ›¿æ¢ä¸ºä½ çš„Telegram Bot Token
		chatID             = "5486452678413"                                      // æ›¿æ¢ä¸ºä½ çš„Chat ID (å¯ä»¥æ˜¯æ•°å­—æˆ–è€…å­—ç¬¦ä¸²ï¼Œå¦‚"@channelname")
	)

	// å¦‚æœæœªå¯ç”¨é€šçŸ¥æˆ–æœªé…ç½®Token/ChatIDï¼Œåˆ™è·³è¿‡å‘é€
	if !enableNotification || botToken == "YOUR_BOT_TOKEN_HERE" || chatID == "YOUR_CHAT_ID_HERE" {
		s.logger.Info("Telegramé€šçŸ¥æœªå¯ç”¨æˆ–æœªé…ç½®å®Œæˆï¼Œè·³è¿‡å‘é€")
		return nil
	}
	// æ„å»ºæ¶ˆæ¯æ–‡æœ¬
	statusEmoji := "âœ…"
	errorInfo := ""

	if status != tasklog.TaskLogStatusCompleted {
		statusEmoji = "âŒ"
		// å¦‚æœæ˜¯å¤±è´¥çŠ¶æ€ï¼Œå°è¯•è·å–é”™è¯¯æ¶ˆæ¯
		if strings.Contains(status, "å¤±è´¥") {
			errorInfo = strings.TrimPrefix(status, "STRM æ–‡ä»¶ç”Ÿæˆå¤±è´¥: ")
			errorInfo = strings.TrimPrefix(errorInfo, "ä¸‹è½½æ–‡ä»¶å¤„ç†å¤±è´¥: ")
		}
	}

	// æ ¼å¼åŒ–æ—¶é—´
	durationStr := ""
	if duration > 0 {
		hours := duration / 3600
		minutes := (duration % 3600) / 60
		seconds := duration % 60

		if hours > 0 {
			durationStr = fmt.Sprintf("%då°æ—¶%dåˆ†é’Ÿ%dç§’", hours, minutes, seconds)
		} else if minutes > 0 {
			durationStr = fmt.Sprintf("%dåˆ†é’Ÿ%dç§’", minutes, seconds)
		} else {
			durationStr = fmt.Sprintf("%dç§’", seconds)
		}
	}

	// æå–ç»Ÿè®¡æ•°æ®ï¼Œç¡®ä¿å®‰å…¨è½¬æ¢
	var (
		totalFiles     int
		generatedFiles int
		skippedFiles   int
		metadataFiles  int
		subtitleFiles  int
	)

	// ç±»å‹å®‰å…¨çš„è½¬æ¢
	if v, ok := stats["total_file"].(int); ok {
		totalFiles = v
	}
	if v, ok := stats["generated_file"].(int); ok {
		generatedFiles = v
	}
	if v, ok := stats["skip_file"].(int); ok {
		skippedFiles = v
	}
	if v, ok := stats["metadata_count"].(int); ok {
		metadataFiles = v
	}
	if v, ok := stats["subtitle_count"].(int); ok {
		subtitleFiles = v
	}

	// æ„å»ºæ¶ˆæ¯
	// ä¸ºçŠ¶æ€æ–‡æœ¬è®¾ç½®æ›´å‹å¥½çš„æ˜¾ç¤º
	statusDisplay := "æˆåŠŸ"
	if status != tasklog.TaskLogStatusCompleted {
		statusDisplay = "å¤±è´¥"
	}

	// æ·»åŠ é”™è¯¯ä¿¡æ¯éƒ¨åˆ†(å¦‚æœæœ‰)
	errorPart := ""
	if errorInfo != "" {
		errorPart = fmt.Sprintf("\n\nâš ï¸ *é”™è¯¯ä¿¡æ¯*\n`%s`", errorInfo)
	}

	message := fmt.Sprintf("ğŸ¬ *AList2Strm ä»»åŠ¡é€šçŸ¥* %s\n\n"+
		"ğŸ“‹ *ä»»åŠ¡è¯¦æƒ…*\n"+
		"â”œ åç§°: `%s`\n"+
		"â”œ çŠ¶æ€: %s *%s*\n"+
		"â”” ç”¨æ—¶: `%s`\n\n"+
		"ğŸ“Š *æ–‡ä»¶ç»Ÿè®¡*\n"+
		"â”œ æ€»æ–‡ä»¶: `%d` ä¸ª\n"+
		"â”œ å·²ç”Ÿæˆ: `%d` ä¸ª\n"+
		"â”œ å·²è·³è¿‡: `%d` ä¸ª\n"+
		"â”œ å…ƒæ•°æ®: `%d` ä¸ª\n"+
		"â”” å­—å¹•: `%d` ä¸ª\n\n"+
		"ğŸ“ *è·¯å¾„ä¿¡æ¯*\n"+
		"â”œ æºè·¯å¾„: `%s`\n"+
		"â”” ç›®æ ‡è·¯å¾„: `%s`%s",
		statusEmoji,
		taskInfo.Name,
		statusEmoji,
		statusDisplay,
		durationStr,
		totalFiles,
		generatedFiles,
		skippedFiles,
		metadataFiles,
		subtitleFiles,
		taskInfo.SourcePath,
		taskInfo.TargetPath,
		errorPart)

	// URLç¼–ç æ¶ˆæ¯
	encodedMessage := url.QueryEscape(message)

	// æ„å»ºAPI URL (ä½¿ç”¨Markdownè§£ææ¨¡å¼)
	apiURL := fmt.Sprintf("https://api.telegram.org/bot%s/sendMessage?chat_id=%s&text=%s&parse_mode=Markdown",
		botToken, chatID, encodedMessage)

	// å‘é€HTTPè¯·æ±‚
	client := &http.Client{Timeout: 10 * time.Second}
	resp, err := client.Get(apiURL)
	if err != nil {
		s.logger.Error("å‘é€Telegramé€šçŸ¥å¤±è´¥", zap.Error(err))
		return err
	}
	defer resp.Body.Close()

	// æ£€æŸ¥å“åº”çŠ¶æ€
	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		s.logger.Error("Telegram APIè¿”å›é”™è¯¯",
			zap.Int("status", resp.StatusCode),
			zap.String("response", string(body)))
		return fmt.Errorf("telegram APIè¿”å›é”™è¯¯: %d", resp.StatusCode)
	}

	s.logger.Info("Telegramé€šçŸ¥å‘é€æˆåŠŸ",
		zap.String("taskName", taskInfo.Name),
		zap.String("status", status))

	return nil
}

// processStrmFileQueue å¤„ç† STRM æ–‡ä»¶ç”Ÿæˆé˜Ÿåˆ—ï¼ˆå¹¶å‘å¤„ç†ï¼‰
// å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ processStrmFileQueueAsync
// nolint:unused
// ä¿ç•™æ­¤æ–¹æ³•æ˜¯ä¸ºäº†å…¼å®¹æ€§
func (s *StrmGeneratorService) processStrmFileQueue(taskInfo *task.Task, strmConfig *StrmConfig, taskLogID uint) error {
	s.queue.FilesMutex.RLock()
	totalStrmFiles := len(s.queue.StrmFiles)
	s.queue.FilesMutex.RUnlock()

	if totalStrmFiles == 0 {
		s.logger.Info("æ²¡æœ‰åª’ä½“æ–‡ä»¶éœ€è¦ç”Ÿæˆ STRM")
		s.stats.Mutex.Lock()
		s.stats.StrmProcessingDone = true
		s.stats.Mutex.Unlock()
		return nil
	}

	s.logger.Info("å¼€å§‹å¹¶å‘ç”ŸæˆSTRMæ–‡ä»¶",
		zap.Int("åª’ä½“æ–‡ä»¶æ•°", totalStrmFiles))

	// è®¾ç½®å¹¶å‘æ•°
	concurrency := 100 // å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ï¼Œæˆ–ä»é…ç½®ä¸­è¯»å–
	if concurrency <= 0 {
		concurrency = 100
	}
	if concurrency > totalStrmFiles {
		concurrency = totalStrmFiles
	}

	// åˆ›å»ºä»»åŠ¡å’Œç»“æœé€šé“
	jobChan := make(chan FileEntry, totalStrmFiles)
	resultChan := make(chan FileProcessResult, totalStrmFiles)

	// å¯åŠ¨å·¥ä½œåç¨‹æ± 
	var wg sync.WaitGroup
	wg.Add(concurrency)

	for i := 0; i < concurrency; i++ {
		go func() {
			defer wg.Done()
			for entry := range jobChan {
				// åªå¤„ç†åª’ä½“æ–‡ä»¶ï¼Œç”ŸæˆSTRMæ–‡ä»¶
				processed := s.processFile(entry.File, entry.FileType, taskInfo, strmConfig, taskLogID, entry.SourcePath, entry.TargetPath)

				// å‘é€ç»“æœ
				resultChan <- FileProcessResult{
					Entry:     entry,
					Processed: processed,
					FileType:  entry.FileType,
					Success:   processed.Success,
				}
			}
		}()
	}

	// å¤åˆ¶ STRM æ–‡ä»¶é˜Ÿåˆ—ä»¥é¿å…é”å†²çª
	s.queue.FilesMutex.RLock()
	strmFiles := make([]FileEntry, len(s.queue.StrmFiles))
	copy(strmFiles, s.queue.StrmFiles)
	s.queue.FilesMutex.RUnlock()

	// æäº¤ä»»åŠ¡
	go func() {
		// æäº¤åª’ä½“æ–‡ä»¶
		for _, entry := range strmFiles {
			jobChan <- entry
		}

		// å…³é—­ä»»åŠ¡é€šé“ï¼Œè¡¨ç¤ºæ²¡æœ‰æ›´å¤šä»»åŠ¡
		close(jobChan)

		// ç­‰å¾…æ‰€æœ‰å·¥ä½œåç¨‹å®Œæˆ
		wg.Wait()

		// å…³é—­ç»“æœé€šé“
		close(resultChan)
	}()

	// æ”¶é›†å¤„ç†ç»“æœ
	for result := range resultChan {
		// ç¡®å®šä½¿ç”¨çš„ç›®æ ‡è·¯å¾„
		targetPath := result.Processed.TargetPath

		// è®°å½•æ–‡ä»¶å†å²
		s.recordFileHistory(
			taskInfo.ID,
			taskLogID,
			result.Entry.File,
			result.Entry.SourcePath,
			targetPath,
			result.FileType,
			result.Success,
		)

		// ç»Ÿè®¡ç»“æœ
		s.stats.Mutex.Lock()
		if result.Success {
			s.stats.GeneratedFiles++
		} else {
			s.stats.SkippedFiles++
		}
		s.stats.Mutex.Unlock()

		// å®šæœŸæ›´æ–°ä»»åŠ¡æ—¥å¿—
		if s.stats.GeneratedFiles%100 == 0 || s.stats.SkippedFiles%100 == 0 {
			s.stats.Mutex.RLock()
			updateData := map[string]interface{}{
				"generated_file": s.stats.GeneratedFiles,
				"skip_file":      s.stats.SkippedFiles,
			}
			s.stats.Mutex.RUnlock()

			if updateErr := repository.TaskLog.UpdatePartial(taskLogID, updateData); updateErr != nil {
				s.logger.Error("æ›´æ–°ä»»åŠ¡æ—¥å¿—è¿›åº¦å¤±è´¥", zap.Error(updateErr))
			}
		}
	}

	// æ ‡è®° STRM å¤„ç†å®Œæˆ
	s.stats.Mutex.Lock()
	s.stats.StrmProcessingDone = true
	s.stats.Mutex.Unlock()

	s.logger.Info("STRM æ–‡ä»¶ç”Ÿæˆé˜Ÿåˆ—å¤„ç†å®Œæˆ",
		zap.Int("ç”Ÿæˆæ–‡ä»¶æ•°", s.stats.GeneratedFiles))

	return nil
}

// processDownloadFileQueue å¤„ç†ä¸‹è½½æ–‡ä»¶é˜Ÿåˆ—ï¼ˆä¸²è¡Œå¤„ç†ï¼Œå¸¦å»¶è¿Ÿï¼‰
func (s *StrmGeneratorService) processDownloadFileQueue(taskInfo *task.Task, strmConfig *StrmConfig, taskLogID uint) error {
	s.queue.FilesMutex.RLock()
	totalDownloadFiles := len(s.queue.DownloadFiles)
	s.queue.FilesMutex.RUnlock()

	if totalDownloadFiles == 0 {
		s.logger.Info("æ²¡æœ‰æ–‡ä»¶éœ€è¦ä¸‹è½½")
		s.stats.Mutex.Lock()
		s.stats.DownloadProcessingDone = true
		s.stats.Mutex.Unlock()
		return nil
	}

	s.logger.Info("å¼€å§‹ä¸²è¡Œå¤„ç†ä¸‹è½½ä»»åŠ¡",
		zap.Int("ä¸‹è½½æ–‡ä»¶æ€»æ•°", totalDownloadFiles))

	// å¤åˆ¶ä¸‹è½½é˜Ÿåˆ—ä»¥é¿å…é”å†²çª
	s.queue.FilesMutex.RLock()
	downloadFiles := make([]FileEntry, len(s.queue.DownloadFiles))
	copy(downloadFiles, s.queue.DownloadFiles)
	s.queue.FilesMutex.RUnlock()

	// ä¸²è¡Œå¤„ç†æ¯ä¸ªä¸‹è½½é¡¹ï¼Œå¸¦é—´éš”å»¶è¿Ÿ
	for i, entry := range downloadFiles {
		// æ·»åŠ éšæœºå»¶è¿Ÿ(1-3ç§’)ï¼Œé˜²æ­¢ç½‘ç›˜é£æ§
		if i > 0 {
			// è®¾ç½®éšæœºå»¶è¿Ÿï¼Œæ›´å¥½åœ°æ¨¡æ‹Ÿäººå·¥æ“ä½œ
			randomDelay := time.Duration(1000+(time.Now().UnixNano()%2000)) * time.Millisecond
			s.logger.Info("ç­‰å¾…éšæœºå»¶è¿Ÿ", zap.Duration("delay", randomDelay))
			time.Sleep(randomDelay)
		}

		// å¤„ç†æ–‡ä»¶
		processed := s.processFile(entry.File, entry.FileType, taskInfo, strmConfig, taskLogID, entry.SourcePath, entry.TargetPath)

		// è®°å½•æ–‡ä»¶å†å²
		s.recordFileHistory(taskInfo.ID, taskLogID, entry.File, entry.SourcePath, processed.TargetPath, entry.FileType, processed.Success)

		// æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
		s.stats.Mutex.Lock()
		if processed.Success {
			if entry.FileType == FileTypeSubtitle {
				s.stats.SubtitleProcessed++
			} else if entry.FileType == FileTypeMetadata {
				s.stats.MetadataProcessed++
			}
		} else {
			s.stats.SkippedFiles++
		}
		s.stats.Mutex.Unlock()

		// æ¯å¤„ç† 10 ä¸ªæ–‡ä»¶æ›´æ–°ä¸€æ¬¡æ•°æ®åº“
		if (i+1)%10 == 0 {
			s.stats.Mutex.RLock()
			updateData := map[string]interface{}{
				"subtitle_count": s.stats.SubtitleProcessed,
				"metadata_count": s.stats.MetadataProcessed,
				"skip_file":      s.stats.SkippedFiles,
			}
			s.stats.Mutex.RUnlock()

			if updateErr := repository.TaskLog.UpdatePartial(taskLogID, updateData); updateErr != nil {
				s.logger.Error("æ›´æ–°ä»»åŠ¡æ—¥å¿—è¿›åº¦å¤±è´¥", zap.Error(updateErr))
			}

			s.logger.Info("ä¸‹è½½é˜Ÿåˆ—å¤„ç†è¿›åº¦",
				zap.Int("å·²å¤„ç†", i+1),
				zap.Int("æ€»æ•°", totalDownloadFiles),
				zap.Int("å­—å¹•æ–‡ä»¶", s.stats.SubtitleProcessed),
				zap.Int("å…ƒæ•°æ®æ–‡ä»¶", s.stats.MetadataProcessed))
		}
	}

	// æ ‡è®°ä¸‹è½½å¤„ç†å®Œæˆ
	s.stats.Mutex.Lock()
	s.stats.DownloadProcessingDone = true
	s.stats.Mutex.Unlock()

	s.logger.Info("ä¸‹è½½æ–‡ä»¶é˜Ÿåˆ—å¤„ç†å®Œæˆ",
		zap.Int("å­—å¹•æ–‡ä»¶", s.stats.SubtitleProcessed),
		zap.Int("å…ƒæ•°æ®æ–‡ä»¶", s.stats.MetadataProcessed))

	return nil
}

// processStrmFileQueueAsync å¼‚æ­¥å¤„ç†STRMæ–‡ä»¶é˜Ÿåˆ—ï¼ˆå¹¶å‘å¤„ç†ï¼‰ï¼Œå¯ä»¥åœ¨ç›®å½•æ‰«ææ—¶å°±å¼€å§‹å¤„ç†
func (s *StrmGeneratorService) processStrmFileQueueAsync(taskInfo *task.Task, strmConfig *StrmConfig, taskLogID uint, scanDoneChan chan bool) error {
	// è®¾ç½®å¹¶å‘æ•°
	const defaultConcurrency = 50
	// TODO: æœªæ¥å¯è€ƒè™‘ä»ä»»åŠ¡é…ç½®æˆ–å…¨å±€é…ç½®ä¸­è¯»å–å¹¶å‘å‚æ•°
	concurrency := defaultConcurrency

	s.logger.Info("å¯åŠ¨STRMæ–‡ä»¶å¼‚æ­¥å¤„ç†åç¨‹",
		zap.Int("å¹¶å‘æ•°", concurrency))

	// åˆ›å»ºä»»åŠ¡å’Œç»“æœé€šé“
	// TODO: æœªæ¥å¯è€ƒè™‘å°†é€šé“å¤§å°è®¾ç½®ä¸ºå¯é…ç½®å‚æ•°ï¼Œé¿å…è¶…å¤§ç›®å½•å¤„ç†æ—¶å†…å­˜å ç”¨è¿‡å¤š
	const channelSize = 1000
	jobChan := make(chan FileEntry, channelSize)            // ç¼“å†²é˜Ÿåˆ—ï¼Œç”¨äºæ¥æ”¶æ‰«æåˆ°çš„æ–‡ä»¶
	resultChan := make(chan FileProcessResult, channelSize) // ç»“æœé˜Ÿåˆ—

	// å¯åŠ¨å·¥ä½œåç¨‹æ± 
	var wg sync.WaitGroup
	wg.Add(concurrency)

	for i := 0; i < concurrency; i++ {
		go func() {
			defer wg.Done()
			for entry := range jobChan {
				// å¤„ç†åª’ä½“æ–‡ä»¶ï¼Œç”ŸæˆSTRMæ–‡ä»¶
				processed := s.processFile(entry.File, entry.FileType, taskInfo, strmConfig, taskLogID, entry.SourcePath, entry.TargetPath)

				// å‘é€ç»“æœ
				resultChan <- FileProcessResult{
					Entry:     entry,
					Processed: processed,
					FileType:  entry.FileType,
					Success:   processed.Success,
				}
			}
		}()
	}

	// å¯åŠ¨ç»“æœæ”¶é›†åç¨‹
	var resultWg sync.WaitGroup
	resultWg.Add(1)
	go func() {
		defer resultWg.Done()
		for result := range resultChan {
			// ç¡®å®šä½¿ç”¨çš„ç›®æ ‡è·¯å¾„
			targetPath := result.Processed.TargetPath

			// è®°å½•æ–‡ä»¶å†å²
			s.recordFileHistory(
				taskInfo.ID,
				taskLogID,
				result.Entry.File,
				result.Entry.SourcePath,
				targetPath,
				result.FileType,
				result.Success,
			)

			// ç»Ÿè®¡ç»“æœ
			s.stats.Mutex.Lock()
			if result.Success {
				s.stats.GeneratedFiles++
			} else {
				s.stats.SkippedFiles++
			}
			s.stats.Mutex.Unlock()

			// å®šæœŸæ›´æ–°ä»»åŠ¡æ—¥å¿—
			if s.stats.GeneratedFiles%100 == 0 || s.stats.SkippedFiles%100 == 0 {
				s.stats.Mutex.RLock()
				updateData := map[string]interface{}{
					"generated_file": s.stats.GeneratedFiles,
					"skip_file":      s.stats.SkippedFiles,
				}
				s.stats.Mutex.RUnlock()

				if updateErr := repository.TaskLog.UpdatePartial(taskLogID, updateData); updateErr != nil {
					s.logger.Error("æ›´æ–°ä»»åŠ¡æ—¥å¿—è¿›åº¦å¤±è´¥", zap.Error(updateErr))
				}
			}
		}
	}()

	// å¯åŠ¨é˜Ÿåˆ—ç›‘å¬åç¨‹ï¼Œå°†æ–‡ä»¶å‘é€åˆ°å·¥ä½œåç¨‹
	go func() {
		scanDone := false

		// æŒç»­ç›‘å¬ç›´åˆ°æ‰«æç»“æŸä¸”é˜Ÿåˆ—ä¸ºç©º
		for !scanDone || s.queue.hasStrmFiles() {
			// å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶å¯å¤„ç†
			if s.queue.hasStrmFiles() {
				// è·å–å¹¶åˆ é™¤é˜Ÿåˆ—ä¸­çš„ä¸€æ‰¹æ–‡ä»¶
				batch := s.queue.getAndRemoveStrmFileBatch(100)
				if len(batch) > 0 {
					s.logger.Debug("æäº¤ä¸€æ‰¹STRMæ–‡ä»¶è¿›è¡Œå¤„ç†", zap.Int("æ•°é‡", len(batch)))
					for _, entry := range batch {
						jobChan <- entry
					}
				}
			}

			// æ£€æŸ¥æ‰«ææ˜¯å¦ç»“æŸ
			select {
			case _, ok := <-scanDoneChan:
				if !ok {
					// é€šé“å…³é—­ï¼Œæ‰«æç»“æŸ
					scanDone = true
				}
			default:
				// é€šé“æœªå…³é—­ï¼Œä¼‘æ¯ä¸€ä¸‹å†æ£€æŸ¥
				time.Sleep(50 * time.Millisecond)
			}
		}

		// å…³é—­ä»»åŠ¡é€šé“ï¼Œè¡¨ç¤ºæ²¡æœ‰æ›´å¤šä»»åŠ¡
		close(jobChan)

		// ç­‰å¾…æ‰€æœ‰å·¥ä½œåç¨‹å®Œæˆ
		wg.Wait()

		// å…³é—­ç»“æœé€šé“
		close(resultChan)

		// ç­‰å¾…ç»“æœæ”¶é›†å®Œæˆ
		resultWg.Wait()
	}()

	// ç­‰å¾…æ‰€æœ‰å¤„ç†å®Œæˆ
	resultWg.Wait()

	// æ ‡è®° STRM å¤„ç†å®Œæˆ
	s.stats.Mutex.Lock()
	s.stats.StrmProcessingDone = true
	s.stats.Mutex.Unlock()

	s.logger.Info("STRM æ–‡ä»¶ç”Ÿæˆé˜Ÿåˆ—å¤„ç†å®Œæˆ",
		zap.Int("ç”Ÿæˆæ–‡ä»¶æ•°", s.stats.GeneratedFiles))

	return nil
}

// hasStrmFiles æ£€æŸ¥é˜Ÿåˆ—ä¸­æ˜¯å¦æœ‰STRMæ–‡ä»¶
func (q *FileProcessQueue) hasStrmFiles() bool {
	q.FilesMutex.RLock()
	defer q.FilesMutex.RUnlock()
	return len(q.StrmFiles) > 0
}

// getAndRemoveStrmFileBatch è·å–å¹¶ç§»é™¤ä¸€æ‰¹STRMæ–‡ä»¶
func (q *FileProcessQueue) getAndRemoveStrmFileBatch(batchSize int) []FileEntry {
	q.FilesMutex.Lock()
	defer q.FilesMutex.Unlock()

	if len(q.StrmFiles) == 0 {
		return []FileEntry{}
	}

	// ç¡®å®šæ‰¹æ¬¡å¤§å°
	size := batchSize
	if size > len(q.StrmFiles) {
		size = len(q.StrmFiles)
	}

	// è·å–æ‰¹æ¬¡
	batch := make([]FileEntry, size)
	copy(batch, q.StrmFiles[:size])

	// ç§»é™¤å·²è·å–çš„æ–‡ä»¶
	q.StrmFiles = q.StrmFiles[size:]

	return batch
}
